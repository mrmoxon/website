export const bioText = `

<br>
<br>
<br>
<ul>
  <li>Some important things I believe in:
    <ul>
        <li>It is our moral duty to help reshape the universe to our preferences.</li>
        <li>Real progress in society depends on our ability to upgrade deeply held beliefs.</li>
        <li>The audacity to grand challenges stems from genuine excitement for the work itself.</li>
        <li>Innovation and agility thrive in small, focused groups.</li>
    </ul>
  </li>
</ul>
<ul>
  <li>The alignment problem defines the core behaviour of any civilisation.
    <ul>
        <li>It is the triple point of "paleolithic emotions, medieval institutions and godlike technology."</li>
        <li>Unchecked technological power converges on pure AGI, which humans in '24 aren't ready for.</li>
        <li>Transformers offer a stable and scalable paradigm for early 'AGI' by '30.</li>
        <li>Digital platforms proliferate hyperstimuli, both actively and by nature. Tiktok is 0.5D wireheading.</li>
    </ul>
  </li>
</ul>
<ul>
  <li>Ultimate promise of LLMs is agents. 
  <ul>
    <li>Ultimate promise of agents is auto-science.</li>
    <li>GPT to agent(s) is like going from "write me an essay" to "make me a dyson syphere."</li>
    <li>LLMs are one step closer to a shared plane of information. Next is the neurological interface.</li>
  </ul>
  </li>
</ul>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<ul>
  <li>Victimless crimes wouldn't exist with perfect information./ in a more efficient government with the individual autonomy as arbiter.</li>
  <li>Three universal ways to measure civilisational progress and scalability: Kardashev Scale, Alignment Trifecta/Coefficient/Factor (cohesion between trifecta of individuals, institutions, and technology), and Assembly Theory/Complexity Coefficient (architecture).
    <ul>
      <li>Alignment Factor is a measure of cohesion with how society's biology, institutions, and technology are aligned. This is connected to their cohesiveness and synergy with their environment, the rules and freedoms we govern by, and the tools we develop to influence our environment.</li>
      <li>Progress is not just about advancing in one area, but about ensuring that these advances improve our lives and are in balance with human needs to societal values. Also, if your technological progress is tangential to the nature of your other two components, you are doomed for derailment.</li>
      <li>Assembly Theory measures the complexity of the civilisational system; a measure of the nature of the civilisation (we could have Kardashev Type 0 but superhigh complexity).</li>
    </ul>
  </li>
</ul>
<br>

<br>
<br>
<ul>
  <li>Path of civilisation:
  <ul>
    <li>The alignment problem defines the core behaviour of our (and all) civilisation.</li>
    <li>It is trifecta, "We have paleolithic emotions, medieval institutions and godlike technology."</li>
    <li>It is our moral duty to reshape the universe to our preferences.</li>
    <li>Unchecked technological power converges on pure AGI, which humans in 2024 cannot handle.</li>
    <li>Transformers offer a stable and scalable paradigm for capable AI intelligence by '30 (v1 "AGI").</li>
  </ul>
  </li>
</ul>
<ul>
  <li>Some thoughts on motives:
    <ul>
        <li>Better to derive satisfaction from the continual refinement and expansion of your ideas.</li>
        <li>Real progress depends on our ability to shift deeply held and imprecise beliefs.</li>
        <li>The decision to tackle grand challenges stems most organically from genuine excitement for the work itself.</li>
        <li>Innovation and agility thrive in small, focused groups.</li>
        <li>Education in the information age must transcend traditional boundaries.</li>
    </ul>
  </li>
</ul>
<ul>
  <li>Lessions from research:
    <ul>
        <li>Ultimate promise of LLMs is agents. Ultimate promise of agents is autoscience.</li>
        <li>gpt to agent(s) upgrades prompting from "write me an essay" to "make me a dyson syphere."</li>
        <li>Digital platforms proliferate hyperstimuli, both actively and by nature. Tiktok is 0.5D wireheading.</li>
        <li>LLMs tread closer to true natural abstraction. Next is the neurological interface.</li>
    </ul>
  </li>
</ul>
<ul>
  <li>Lessions from economics:
    <ul>
      <li>EMH is weak at best, all opportunities emerge in the gaps of market rationality.</li>
      <li>The fate of billions is steered overwhelmingly by the work of a few.</li>
      <li>Regulation is used best when smoothing unhealthy competitive forces (reigning in Moloch).</li>
      <li>Concentrations of power are typically dangerous and wasteful, but maximise investor returns.</li>
    </ul>
  </li>
</ul>
<br>
<ul>
  <li>Victimless crimes wouldn't exist with perfect information./ in a more efficient government with the individual autonomy as arbiter.</li>
  <li>Three universal ways to measure civilisational progress and scalability: Kardashev Scale, Alignment Trifecta/Coefficient/Factor (cohesion between trifecta of individuals, institutions, and technology), and Assembly Theory/Complexity Coefficient (architecture).
    <ul>
      <li>Alignment Factor is a measure of cohesion with how society's biology, institutions, and technology are aligned. This is connected to their cohesiveness and synergy with their environment, the rules and freedoms we govern by, and the tools we develop to influence our environment.</li>
      <li>Progress is not just about advancing in one area, but about ensuring that these advances improve our lives and are in balance with human needs to societal values. Also, if your technological progress is tangential to the nature of your other two components, you are doomed for derailment.</li>
      <li>Assembly Theory measures the complexity of the civilisational system; a measure of the nature of the civilisation (we could have Kardashev Type 0 but superhigh complexity).</li>
    </ul>
  </li>
</ul>
<br>


Alignment is a multi-agent issue that will always evolve with society and technology.
We should model the universe as a canvas, bounded at the edge only by the laws of physics.

<br>
<br>
Path of civilisation:
<ul>
  <li>The alignment problem defines the core behaviour of our (and all) civilisation.</li>
  <li>It is trifecta: 'We have Paleolithic emotions, medieval institutions and godlike technology' (E. Wilson).</li>
    <ul>
      <li>The trajectory of civilisation is fundamentally shaped by our accumulating knowledge, which serves as a double-edged swordâ€”empowering us to achieve the miraculous while exposing us to escalating existential risks.</li>
      <li>Striking a balance between stability and creative disruption is the role of regulation.</li>
    </ul>
  <li>It is our moral duty to align ourselves with technology(?) and reshape the universe to our preferences, harnessing the laws of physics to guide entropy(?). Alignment is a multi-agent issue that will always evolve with society and technology. We should model the universe as a canvas, bounded at the edge only by the laws of physics.</li>
  <li>Unchecked technological power converges on pure AGI, which humans in 2024 cannot handle.</li>
  <li>Transformers offer a stable and scalable paradigm for artificially capable intelligence by '30 (v1 "AGI").</li>
</ul>
<br>

Lessions from economics:
<ul>
  <li>The efficient market hypothesis (EMH) is weak.</li>
  <li>The richest opportunities emerge in the gaps of market rationality.</li>
  <li>The fate of billions is surprisingly steered by the decisions of a few. In many cases it's more accurate to model the world as 500 people than 8 billion - Nat Friedman. Instead, we should empower and extend the information processing capabilities of all humans, not a top percentile.</li>
  <li>Concentrations of power are typically dangerous, but always the best way/heuristic to maximise returns.</li>
  <li>Digital platforms proliferate hyperstimuli, both actively and by nature. This converges at wireheading.</li>
</ul>
<br>

Some other thoughts:
<ul>
  <li>Progress hinges on our willingness to question deeply held beliefs and the courage to ask more meaningful questions. There is no fix-all.</li>
  <li>Better to derive satisfaction from the continual refinement and expansion of your ideas.</li>
  <li>An audacity to tackle grand challenges best stems from a genuine excitement for the work itself.</li>
  <li>Innovation and agility thrive in small, focused groups. The bloat of bureaucracy stifles creativity and efficiency: every organisation could achieve more with less. Innovators Dilemma II.</li>
  <li>Education must transcend traditional boundaries.</li>
  <li>We are at the second highest level of natural abstraction with machines. Next is the neurological interface.</li>
</ul>
<br>

<ul>
  <li>Victimless crimes wouldn't exist in a more efficient government with the individual autonomy as arbiter.</li>
  <li>Three universal ways to measure civilisational progress and scalability: Kardashev Scale, Alignment Trifecta/Coefficient/Factor (cohesion between trifecta of individuals, institutions, and technology), and Assembly Theory/Complexity Coefficient (architecture).
    <ul>
      <li>Alignment Factor is a measure of cohesion with how society's biology, institutions, and technology are aligned. This is connected to their cohesiveness and synergy with their environment, the rules and freedoms we govern by, and the tools we develop to influence our environment.</li>
      <li>Progress is not just about advancing in one area, but about ensuring that these advances improve our lives and are in balance with human needs to societal values. Also, if your technological progress is tangential to the nature of your other two components, you are doomed for derailment.</li>
      <li>Assembly Theory measures the complexity of the civilisational system; a measure of the nature of the civilisation (we could have Kardashev Type 0 but superhigh complexity).</li>
    </ul>
  </li>
</ul>
<br>
`;